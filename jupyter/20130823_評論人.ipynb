{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import requests as rs\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from datetime import date,datetime\n",
    "import json\n",
    "# from splinter import Browser\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import NoAlertPresentException\n",
    "import unittest, time, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 原始版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# f= open('e:/jupyter/TRAVEL/tripadvisor_1_14_test.txt','w')\n",
    "home_url = 'https://www.tripadvisor.com.tw'\n",
    "base_url='https://www.tripadvisor.com.tw/Attractions-g293913-Activities-oa{}-Taipei.html#ATTRACTION_LIST'\n",
    "textNo=0\n",
    "#景點分頁下載\n",
    "for page in xrange(0,14,+1):\n",
    "    title=(base_url.format(page*30))\n",
    "#     print(title)\n",
    "    res=rs.get(title)\n",
    "    soup=bs(res.text,'html5lib')\n",
    "    articles = soup.select('.photo_booking.non_generic .photo_link')\n",
    "#分頁網站連接下載\n",
    "    for article in articles:\n",
    "        try:\n",
    "            url= home_url + article['href']\n",
    "        except IndexError:\n",
    "            url = 'null'\n",
    "#         print(url)\n",
    "        res=rs.get(url)\n",
    "        soup=bs(res.text,'html5lib')\n",
    "        inner_url = url.replace('Reviews-','Reviews-or{}-')\n",
    "        content = inner_url.split('-')[3].split('-')[0]\n",
    "\n",
    "#             print(content)\n",
    "#             if content != 'Reviews':\n",
    "#                 print(inner_url = 'null')\n",
    "\n",
    "        total_page =int(soup.select('.unified.pagination .pageNum.taLnk')[-1]['data-page-number'])\n",
    "        print(type(total_page))\n",
    "        for page in xrange(0,total_page-1):\n",
    "            inner_title = (inner_url.format(page*10))    \n",
    "#             print(inner_title)    \n",
    "            inner_page_res = rs.get(inner_title)\n",
    "            inner_page_bs = bs(inner_page_res.text ,'html5lib')\n",
    "            total_userId = len(inner_page_bs.select('div.memberBadging.g10n'))\n",
    "\n",
    "            for num in range(0,total_userId,+1):\n",
    "            #使用者ID\n",
    "                try:\n",
    "                    UID = inner_page_bs.select('div.memberBadging.g10n')[num].select('div')[0]['id']\\\n",
    "                        .split('-')[0]\\\n",
    "                        .replace('UID_','')\n",
    "\n",
    "\n",
    "\n",
    "        #     #================================================================================================ \n",
    "         #各使用者簡介\n",
    "\n",
    "                    user_url = 'https://www.tripadvisor.com.tw/MemberOverlay?Mode=owa&uid={}&c=&src=&fus=false&partner=false&LsoId=&metaReferer=Attraction_Review'\n",
    "                    user_infopage = (user_url.format(UID))\n",
    "        #                        print(user_infopage)\n",
    "                    user_res = rs.get(user_infopage)\n",
    "                    user_soup = bs(user_res.text,'html5lib')\n",
    "    #                                 print(user_soup.select('div.memberreviewbadge')[0].select('div.badgeinfo')[0].text)\n",
    "                    def user_function (a,b):\n",
    "                        return user_soup.select(a)[0].select(b)[0].text\n",
    "                  #使用者簡介\\\n",
    "#                     try:\n",
    "                    user_name = user_function('.memberOverlayRedesign.g10n','.username')\n",
    "                    user_time = user_function('.memberOverlayRedesign.g10n','.memberdescription')\n",
    "                    user_counts = user_function('.memberOverlayRedesign.g10n','.counts') \n",
    "                    user_homepage = home_url + user_soup.select('div.baseNav')[0].select('a')[0]['href']\n",
    "                    user_comments = user_function('.lowerMemberOverlay.wrap','.reviewchart.wrap.container')\n",
    "#                     print(user_comments+user_counts,'\\n')#使用者評論數\n",
    "#                         print(user_name)#使用者名字\n",
    "#                         print(user_time)#只用者註冊時間\n",
    "#                         print(user_homepage)#只用者個人頁面網址\n",
    "#===============================================================================================================\n",
    "                    #使用者評論截取\n",
    "                    broswer = webdriver.Firefox()\n",
    "                    broswer.get(user_homepage)\n",
    "                    broswer.maximize_window()\n",
    "                    # broswer.execute_script('window.scrollTo(0,document.body.scrollHeight);')\n",
    "                    soup = bs(broswer.page_source)\n",
    "                    article = soup.select('li.cs-review')\n",
    "                    page_num = len(soup.select('button.cs-paginate-goto'))\n",
    "                    if page_num > 2:\n",
    "                        while soup.select('button#cs-paginate-next')[0]['class'][0] != 'disabled':\n",
    "                            for i in article:\n",
    "                                title = i.select('.cs-review-location')[0].text\n",
    "                                target = i.select('.cs-review-title')[0].text\n",
    "                                url = home_url+i.select('.cs-review-location a')[0]['href']\n",
    "                                rating = i.select('.cs-review-rating')[0].select('div.rate img')[0]['content']\n",
    "                        #         time.sleep(1) \n",
    "#                                 print(title + target)\n",
    "#                                 print(url)\n",
    "#                                 print('評等'+rating)\n",
    "                            broswer.execute_script('window.scrollTo(0,document.body.scrollHeight);')\n",
    "                            #         broswer.find_element_by_xpath(\"//div[@id='BODYCON']/div[3]/div[4]/div/button[x+2]\").click()\n",
    "                            broswer.find_element_by_id(\"cs-paginate-next\").click()\n",
    "                            soup = bs(broswer.page_source)\n",
    "                            article = soup.select('li.cs-review')\n",
    "                            for i in article:    \n",
    "                                title = i.select('.cs-review-location')[0].text\n",
    "                                title_date = i.select('.cs-review-date')[0].text\n",
    "                                target = i.select('.cs-review-title')[0].text\n",
    "                                url = home_url+i.select('.cs-review-location a')[0]['href']\n",
    "                                rating = i.select('.cs-review-rating')[0].select('div.rate img')[0]['content']\n",
    "                                #使用者發文內容\n",
    "                                user_res2 = rs.get(url)\n",
    "                                user_soup2 = bs(user_res2.text,'html5lib')\n",
    "                                url2 = home_url+user_soup2.select('div.quote a')[0]['href']\n",
    "                                #使用者發文文章的連結\n",
    "                                user_res3 = rs.get(url2) \n",
    "                                user_soup3 = bs(user_res3.text,'html5lib')\n",
    "                                inner_note = user_soup3.select('div.entry')[0].text\n",
    "                                broswer.close()  \n",
    "                        #     broswer.implicitly_wait(3)\n",
    "#                                 print(title + target)\n",
    "#                                 print(title_date)\n",
    "#                                 print(url)\n",
    "#                                 print('評等'+rating)\n",
    "#                                 print(inner_note,'-----------------------------------------')\n",
    "\n",
    "\n",
    "                    else:\n",
    "                        soup = bs(broswer.page_source)\n",
    "                        article = soup.select('li.cs-review')\n",
    "                        for i in article:\n",
    "                            title = i.select('.cs-review-location')[0].text\n",
    "                            title_date = i.select('.cs-review-date')[0].text\n",
    "                            target = i.select('.cs-review-title')[0].text\n",
    "                            url = home_url+i.select('.cs-review-location a')[0]['href']\n",
    "                            rating = i.select('.cs-review-rating')[0].select('div.rate img')[0]['content']\n",
    "                            #使用者發文內容\n",
    "                            user_res2 = rs.get(url)\n",
    "                            user_soup2 = bs(user_res2.text,'html5lib')\n",
    "                            url2 = home_url+user_soup2.select('div.quote a')[0]['href']\n",
    "                            #使用者發文文章的連結\n",
    "                            user_res3 = rs.get(url2) \n",
    "                            user_soup3 = bs(user_res3.text,'html5lib')\n",
    "                            inner_note = user_soup3.select('div.entry')[0].text\n",
    "\n",
    "\n",
    "                    #         time.sleep(1) \n",
    "#                             print(title + target)\n",
    "#                             print(title_date)\n",
    "#                             print(url)\n",
    "#                             print('評等'+rating)\n",
    "#                             print(inner_note,'-----------------------------------------')\n",
    "\n",
    "                    broswer.close()            \n",
    "                except IndexError:\n",
    "                    user_comments = 'null'\n",
    "#                         print(user_homepage)\n",
    "\n",
    "\n",
    "                finally:        \n",
    "\n",
    "#                     print(user_name)#使用者名字\n",
    "#                     print(user_time)#只用者註冊時間\n",
    "#                     print(user_homepage)#只用者個人頁面網址\n",
    "\n",
    "                #使用者個人頁面資訊\n",
    "                    try:\n",
    "                        user_res2 = rs.get(user_homepage)\n",
    "                        user_soup2 = bs(user_res2.text,'html5lib')\n",
    "                        print(\"4\"+user_name_info)\n",
    "                        user_point = user_soup2.select('div.points_info.tripcollectiveinfo')[0].text\n",
    "                        print(\"5\"+user_point)\n",
    "                        user_lv = user_soup2.select('div.level.tripcollectiveinfo')[0].text\n",
    "                        print(\"6\"+user_lv)\n",
    "                        user_badge = user_soup2.select('div.badgeList.badgeListLoggedOut')[0].text\n",
    "                        print(\"7\"+user_badge)\n",
    "                        div = []\n",
    "                        for y in range(0,target_num):\n",
    "                            user_target = user_soup2.select('div.tagBubble.unclickable')[y].text+','\n",
    "#                             div.append(user_target.decode('unicode_escape').encode('utf-8'))\n",
    "                        # broswer.implicitly_wait(3)\n",
    "\n",
    "#     broswer.find_element_by_css_selector(\"button.cs-paginate-goto.active\").click()\n",
    "# time.sleep(2)    \n",
    "\n",
    "\n",
    "\n",
    "                        #使用者評論等級                        \n",
    "                            print((user_target).strip(','))#使用者標籤\n",
    "#                             print(user_name_info+user_point,'\\n')#使用者獲得點數\n",
    "#                             print(user_badge,'\\n')#使用者獲得標章\n",
    "\n",
    "                    except:\n",
    "                       user_target = 'null'\n",
    "\n",
    "\n",
    "                    finally:   \n",
    "                        print(user_name_info+user_point,'\\n')#使用者獲得點數\n",
    "                        print(user_badge,'\\n')#使用者獲得標章\n",
    "\n",
    "\n",
    "                        print('==========================================================')\n",
    "\n",
    "\n",
    "\n",
    "#                         with open('E:/project/test-folder/{}.txt'.format(str(textNo).zfill(8)),'w') as f:\n",
    "#                             f.write(user_name.encode(\"UTF-8\")+\"\\n\"\\\n",
    "#                                     +user_time.encode(\"UTF-8\")+\" \"+user_target.encode('UTF-8')+\"\\n\"\\\n",
    "#                                     +user_name_info.encode('UTF-8')+\" \"+user_point.encode('UTF-8')+\"\\n\"\\\n",
    "#                                     +user_badge.encode(\"UTF-8\")+\"\\n\"\\\n",
    "#                                     +url.encode(\"UTF-8\")+\"\\n\"\\\n",
    "#                                     +user_comments.encode(\"UTF-8\")+\" \"+user_counts.encode(\"UTF-8\")+\"\\n\"\\\n",
    "#                                     +title_date.encode(\"UTF-8\")+\"\\n\"\\\n",
    "#                                     +inner_note.encode(\"UTF-8\")\n",
    "#                                    )\n",
    "#                         textNo += 1    \n",
    "\n",
    "# time.sleep(5)\n",
    "\n",
    "# f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 評論人重複值還沒有解決~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "home_url = 'https://www.tripadvisor.com.tw'\n",
    "base_url='https://www.tripadvisor.com.tw/Attractions-g293913-Activities-oa{}-Taipei.html#ATTRACTION_LIST'\n",
    "textNo=0\n",
    "#景點分頁下載\n",
    "for page in xrange(0,14,+1):\n",
    "    title=(base_url.format(page*30))\n",
    "#     print(title)\n",
    "    res=rs.get(title)\n",
    "    soup=bs(res.text,'html5lib')\n",
    "    for n in soup.select('.photo_booking.non_generic .photo_link'):    \n",
    "    #分頁網站連接下載\n",
    "        try:\n",
    "            url='https://www.tripadvisor.com.tw'+n['href']\n",
    "            if(url.split('_')[1].split('-')[0]=='Review'):\n",
    "                print(url)      \n",
    "            else:\n",
    "                url='null'\n",
    "                print(\"怪怪的\")\n",
    "            #============分頁挑選========#    \n",
    "            res=rs.get(url)\n",
    "            soup=bs(res.text,'html5lib')        \n",
    "            inner_url = url.replace('Reviews-','Reviews-or{}-')\n",
    "#             print(\"1\"+ inner_url)\n",
    "            #==========各景點評論的初始頁==================#\n",
    "            content = inner_url.split('-')[3].split('-')[0]\n",
    "            total_page =int(soup.select('.unified.pagination .pageNum.taLnk')[-1]['data-page-number'])\n",
    "            print(total_page)\n",
    "            #=====各評論的總頁數===================#\n",
    "            for page in xrange(0,total_page-1):\n",
    "                inner_title = (inner_url.format(page*10))    \n",
    "#                 print(\"2\"+ inner_title)\n",
    "                #===========各評論的評論內容========#    \n",
    "                inner_page_res = rs.get(inner_title)\n",
    "                inner_page_bs = bs(inner_page_res.text ,'html5lib')\n",
    "                total_userId = len(inner_page_bs.select('div.memberBadging.g10n'))\n",
    "                for num in range(0,total_userId,+1):               \n",
    "                    try:\n",
    "                       \n",
    "                        UID = inner_page_bs.select('div.memberBadging.g10n')[num].select('div')[0]['id']\\\n",
    "                            .split('-')[0]\\\n",
    "                            .replace('UID_','')\n",
    "                            #使用者ID#\n",
    "                        member_id = UID  \n",
    "                        print(UID)\n",
    "                       \n",
    "                        user_url = 'https://www.tripadvisor.com.tw/MemberOverlay?Mode=owa&uid={}&c=&src=&fus=false&partner=false&LsoId=&metaReferer=Attraction_Review'\n",
    "                        user_infopage = (user_url.format(UID))\n",
    "                        print(user_infopage)\n",
    "                        print(\"++++++++++++++++++++++++++\")\n",
    "                        #各使用者簡介#\n",
    "                        user_res = rs.get(user_infopage)\n",
    "                        user_soup = bs(user_res.text,'html5lib')\n",
    "#                                         print(user_soup.select('div.memberreviewbadge')[0].select('div.badgeinfo')[0].text)\n",
    "                        def user_function (a,b):\n",
    "                            return user_soup.select(a)[0].select(b)[0].text                \n",
    "                        user_name = user_function('.memberOverlayRedesign.g10n','.username')                        \n",
    "#                         print(user_name)                        \n",
    "                        user_time = user_function('.memberOverlayRedesign.g10n','.memberdescription')\n",
    "#                         print(type(user_time))\n",
    "#                         print(\"1\"+user_time)\n",
    "                        user_counts = user_function('.memberOverlayRedesign.g10n','.counts')\n",
    "                        member_remark=user_counts\n",
    "#                         print(\"2\"+member_remark)\n",
    "                        user_homepage = home_url + user_soup.select('div.baseNav')[0].select('a')[0]['href']\n",
    "                        print(user_homepage)\n",
    "                        #使用者個人頁面網址.可以用來做字典剔除\n",
    "#===============================================================================================================# \n",
    "                        #使用者評論截取\n",
    "#                         broswer = webdriver.Firefox()\n",
    "#                         broswer.get(user_homepage)\n",
    "#                         broswer.maximize_window()\n",
    "#                         # broswer.execute_script('window.scrollTo(0,document.body.scrollHeight);')\n",
    "#                         soup = bs(broswer.page_source)\n",
    "#                         article = soup.select('li.cs-review')\n",
    "#                         page_num = len(soup.select('button.cs-paginate-goto'))\n",
    "                        #==========================================#\n",
    "                        print(\"************************\")\n",
    "                        user_res2 = rs.get(user_homepage)\n",
    "                        print(user_res2)\n",
    "                        user_soup2 = bs(user_res2.text,'html5lib')\n",
    "                        user_gender=user_soup2.select('div.modules-membercenter-member-profile')[0].select('div.ageSince')[0].text\n",
    "                        print(\"3\"+user_gender)\n",
    "                        user_country=user_soup2.select('div.modules-membercenter-member-profile')[0].select('div.hometown')[0].text\n",
    "                        print(\"3\"+user_country)\n",
    "                        user_name_info = user_soup2.select('div.modules-membercenter-progress-header')[0].select('div.name')[0].text\n",
    "                        print(\"4\"+user_name_info)\n",
    "                        user_point = user_soup2.select('div.points_info.tripcollectiveinfo')[0].text\n",
    "                        print(\"5\"+user_point)\n",
    "                        user_lv = user_soup2.select('div.level.tripcollectiveinfo')[0].text\n",
    "                        print(\"6\"+user_lv)\n",
    "                        user_badge = user_soup2.select('div.badgeList.badgeListLoggedOut')[0].text\n",
    "                        print(\"7\"+user_badge)\n",
    "#                         target_num = len(user_soup2.select('div.tagBubble.unclickable'))\n",
    "#                         for y in range(0,target_num):\n",
    "#                             user_target = user_soup2.select('div.tagBubble.unclickable')[y].text+','\n",
    "#                         #使用者評論等級                        \n",
    "#                             print((user_target).strip(','))#使用者標籤\n",
    "#                             print(user_name_info+user_point,'\\n')#使用者獲得點數\n",
    "#                             print(user_badge,'\\n')#使用者獲得標章\n",
    "                        \n",
    "                                \n",
    "#                             print(user_name_info+user_point,'\\n')#使用者獲得點數\n",
    "#                             print(user_badge,'\\n')#使用者獲得標章 \n",
    "    # #                     print(user_name)#使用者名字\n",
    "    # #                     print(user_time)#只用者註冊時間\n",
    "    # #                     print(user_homepage)#只用者個人頁面網址\n",
    "\n",
    "#                         broswer.close()            \n",
    "                    except:\n",
    "                        user_target = 'null'\n",
    "                        user_badge='null' \n",
    "                        user_lv='null' \n",
    "#                     finally:\n",
    "#                         print(\"ok1\")\n",
    "        except IndexError:\n",
    "                print(\"=====================\")\n",
    "                print(\"出現Skip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    #===============================================================================================================# \n",
    "    #                     #使用者評論截取\n",
    "    #                     broswer = webdriver.Firefox()\n",
    "    #                     broswer.get(user_homepage)\n",
    "    #                     broswer.maximize_window()\n",
    "    #                     # broswer.execute_script('window.scrollTo(0,document.body.scrollHeight);')\n",
    "    #                     soup = bs(broswer.page_source)\n",
    "    #                     article = soup.select('li.cs-review')\n",
    "    #                     page_num = len(soup.select('button.cs-paginate-goto'))\n",
    "    #                     if page_num > 2:\n",
    "    #                         while soup.select('button#cs-paginate-next')[0]['class'][0] != 'disabled':\n",
    "    #                             for i in article:\n",
    "    #                                 title = i.select('.cs-review-location')[0].text\n",
    "    #                                 target = i.select('.cs-review-title')[0].text\n",
    "    #                                 url = home_url+i.select('.cs-review-location a')[0]['href']\n",
    "    #                                 rating = i.select('.cs-review-rating')[0].select('div.rate img')[0]['content']\n",
    "    #                         #         time.sleep(1) \n",
    "    # #                                 print(title + target)\n",
    "    # #                                 print(url)\n",
    "    # #                                 print('評等'+rating)\n",
    "    #                             broswer.execute_script('window.scrollTo(0,document.body.scrollHeight);')\n",
    "    #                             #         broswer.find_element_by_xpath(\"//div[@id='BODYCON']/div[3]/div[4]/div/button[x+2]\").click()\n",
    "    #                             broswer.find_element_by_id(\"cs-paginate-next\").click()\n",
    "    #                             soup = bs(broswer.page_source)\n",
    "    #                             article = soup.select('li.cs-review')\n",
    "    #                             for i in article:    \n",
    "    #                                 title = i.select('.cs-review-location')[0].text\n",
    "    #                                 title_date = i.select('.cs-review-date')[0].text\n",
    "    #                                 target = i.select('.cs-review-title')[0].text\n",
    "    #                                 url = home_url+i.select('.cs-review-location a')[0]['href']\n",
    "    #                                 rating = i.select('.cs-review-rating')[0].select('div.rate img')[0]['content']\n",
    "    #                                 #使用者發文內容\n",
    "    #                                 user_res2 = rs.get(url)\n",
    "    #                                 user_soup2 = bs(user_res2.text,'html5lib')\n",
    "    #                                 url2 = home_url+user_soup2.select('div.quote a')[0]['href']\n",
    "    #                                 #使用者發文文章的連結\n",
    "    #                                 user_res3 = rs.get(url2) \n",
    "    #                                 user_soup3 = bs(user_res3.text,'html5lib')\n",
    "    #                                 inner_note = user_soup3.select('div.entry')[0].text\n",
    "    # #                                 broswer.close()  \n",
    "    #                         #     broswer.implicitly_wait(3)\n",
    "    # #                                 print(title + target)\n",
    "    # #                                 print(title_date)\n",
    "    # #                                 print(url)\n",
    "    # #                                 print('評等'+rating)\n",
    "    # #                                 print(inner_note,'-----------------------------------------')\n",
    "\n",
    "\n",
    "    #                     else:\n",
    "    #                         soup = bs(broswer.page_source)\n",
    "    #                         article = soup.select('li.cs-review')\n",
    "    #                         for i in article:\n",
    "    #                             title = i.select('.cs-review-location')[0].text\n",
    "    #                             title_date = i.select('.cs-review-date')[0].text\n",
    "    #                             target = i.select('.cs-review-title')[0].text\n",
    "    #                             url = home_url+i.select('.cs-review-location a')[0]['href']\n",
    "    #                             rating = i.select('.cs-review-rating')[0].select('div.rate img')[0]['content']\n",
    "    #                             #使用者發文內容\n",
    "    #                             user_res2 = rs.get(url)\n",
    "    #                             user_soup2 = bs(user_res2.text,'html5lib')\n",
    "    #                             url2 = home_url+user_soup2.select('div.quote a')[0]['href']\n",
    "    #                             #使用者發文文章的連結\n",
    "    #                             user_res3 = rs.get(url2) \n",
    "    #                             user_soup3 = bs(user_res3.text,'html5lib')\n",
    "    #                             inner_note = user_soup3.select('div.entry')[0].text\n",
    "\n",
    "\n",
    "    #                     #         time.sleep(1) \n",
    "    # #                             print(title + target)\n",
    "    # #                             print(title_date)\n",
    "    # #                             print(url)\n",
    "    # #                             print('評等'+rating)\n",
    "    # #                             print(inner_note,'-----------------------------------------')\n",
    "\n",
    "    #                     broswer.close()\n",
    "                    except:\n",
    "                     except IndexError:                        \n",
    "                        user_comments = 'null'\n",
    "                        print(user_homepage)\n",
    "\n",
    "\n",
    "    #                 finally:        \n",
    "                                                    #使用者個人頁面資訊\n",
    "                    try:\n",
    "                        user_res2 = rs.get(user_homepage)\n",
    "                        user_soup2 = bs(user_res2.text,'html5lib')\n",
    "                        user_gender=user_soup2.select('modules-membercenter-member-profile ')[0].select('p')[0].text\n",
    "                        print(\"3\"+user_gender)\n",
    "                        user_name_info = user_soup2.select('div.modules-membercenter-progress-header')[0].select('div.name')[0].text\n",
    "                        print(\"4\"+user_name_info)\n",
    "                        user_point = user_soup2.select('div.points_info.tripcollectiveinfo')[0].text\n",
    "                        print(\"5\"+user_point)\n",
    "                        user_lv = user_soup2.select('div.level.tripcollectiveinfo')[0].text\n",
    "                        print(\"6\"+user_lv)\n",
    "                        user_badge = user_soup2.select('div.badgeList.badgeListLoggedOut')[0].text\n",
    "                        print(\"7\"+user_badge)\n",
    "                        target_num = len(user_soup2.select('div.tagBubble.unclickable'))\n",
    "                        div = []\n",
    "                        for y in range(0,target_num):\n",
    "                            user_target = user_soup2.select('div.tagBubble.unclickable')[y].text+','\n",
    "                        #使用者評論等級                        \n",
    "                            print((user_target).strip(','))#使用者標籤\n",
    "#                             print(user_name_info+user_point,'\\n')#使用者獲得點數\n",
    "#                             print(user_badge,'\\n')#使用者獲得標章\n",
    "                        \n",
    "                                \n",
    "#                             print(user_name_info+user_point,'\\n')#使用者獲得點數\n",
    "#                             print(user_badge,'\\n')#使用者獲得標章 \n",
    "    # #                     print(user_name)#使用者名字\n",
    "    # #                     print(user_time)#只用者註冊時間\n",
    "    # #                     print(user_homepage)#只用者個人頁面網址\n",
    "\n",
    "    #                \n",
    "\n",
    "\n",
    "    #                         print('==========================================================')\n",
    "\n",
    "\n",
    "\n",
    "    #                         with open('E:/project/test-folder/{}.txt'.format(str(textNo).zfill(8)),'w') as f:\n",
    "    #                             f.write(user_name.encode(\"UTF-8\")+\"\\n\"\\\n",
    "    #                                     +user_time.encode(\"UTF-8\")+\" \"+user_target.encode('UTF-8')+\"\\n\"\\\n",
    "    #                                     +user_name_info.encode('UTF-8')+\" \"+user_point.encode('UTF-8')+\"\\n\"\\\n",
    "    #                                     +user_badge.encode(\"UTF-8\")+\"\\n\"\\\n",
    "    #                                     +url.encode(\"UTF-8\")+\"\\n\"\\\n",
    "    #                                     +user_comments.encode(\"UTF-8\")+\" \"+user_counts.encode(\"UTF-8\")+\"\\n\"\\\n",
    "    #                                     +title_date.encode(\"UTF-8\")+\"\\n\"\\\n",
    "    #                                     +inner_note.encode(\"UTF-8\")\n",
    "    #                                    )\n",
    "    #                         textNo += 1    \n",
    "\n",
    "    # time.sleep(5)\n",
    "\n",
    "    # f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = '''Amazon has long favored growth over profits, and in its nearly 22-year lifespan, the company has poured resources into building out a sprawling logistics infrastructure dedicated to giving you what you want almost immediately. Why should you have to wait for days (or, God forbid, leave your house) when you need toilet paper?\n",
    "\n",
    "Stephenie Landry is the force responsible for the instantaneousness of your gratification—as vice president of Amazon Prime Now, she conceptualized how the company would bring one-hour deliveries to life and assembled the team to work on the problem. “We have something at Amazon called the working-backward process,” Landry says. “We write a press release saying what we would announce to the world, and when I was writing the product concept, I wrote that the experience of Prime Now would be ‘magical.’” Since launching in December 2014, the service has gone live in four countries and more than 30 metropolitan areas around the world. And, as rumors swirl that Amazon may also be working on a global delivery network, Prime Now increasingly looks to be a scaled-down version of the company’s long-term play: to be in complete control of the flow of products in its supply chain, from factories in China and India all the way to your doorstep. That grand plan would involve not only trucks, cargo planes, and drones but also hundreds of thousands of humans working in warehouses and as couriers. And if anything like that aspirational picture of Prime Now actually emerges, UPS and FedEx should probably start prepping their contingency plans as soon as, well, now. —Davey Alba\n",
    "'''\n",
    "words = text.split(' ')\n",
    "\n",
    "dic = {}\n",
    "for w in words:\n",
    "    if w not in dic:\n",
    "        dic[w] = 1\n",
    "    else:\n",
    "        dic[w] += 1\n",
    "print(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 評論人重複值還沒有解決~~準備解決版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "home_url = 'https://www.tripadvisor.com.tw'\n",
    "base_url='https://www.tripadvisor.com.tw/Attractions-g293913-Activities-oa{}-Taipei.html#ATTRACTION_LIST'\n",
    "textNo=0\n",
    "#景點分頁下載\n",
    "for page in xrange(0,14,+1):\n",
    "    title=(base_url.format(page*30))\n",
    "#     print(title)\n",
    "    res=rs.get(title)\n",
    "    soup=bs(res.text,'html5lib')\n",
    "    for n in soup.select('.photo_booking.non_generic .photo_link'):    \n",
    "    #分頁網站連接下載\n",
    "        try:\n",
    "            url='https://www.tripadvisor.com.tw'+n['href']\n",
    "            if(url.split('_')[1].split('-')[0]=='Review'):\n",
    "                print(url)      \n",
    "            else:\n",
    "                url='null'\n",
    "                print(\"怪怪的\")\n",
    "            #============分業挑選========#    \n",
    "            res=rs.get(url)\n",
    "            soup=bs(res.text,'html5lib')        \n",
    "            inner_url = url.replace('Reviews-','Reviews-or{}-')\n",
    "#             print(\"1\"+ inner_url)\n",
    "            #==========各景點評論的初始頁==================#\n",
    "            content = inner_url.split('-')[3].split('-')[0]\n",
    "            total_page =int(soup.select('.unified.pagination .pageNum.taLnk')[-1]['data-page-number'])\n",
    "            print(total_page)\n",
    "            #=====各評論的總頁數===================#\n",
    "            for page in xrange(0,total_page-1):\n",
    "                inner_title = (inner_url.format(page*10))    \n",
    "#                 print(\"2\"+ inner_title)\n",
    "                #===========各評論的評論內容========#    \n",
    "                inner_page_res = rs.get(inner_title)\n",
    "                inner_page_bs = bs(inner_page_res.text ,'html5lib')\n",
    "                total_userId = len(inner_page_bs.select('div.memberBadging.g10n'))\n",
    "                for num in range(0,total_userId,+1):               \n",
    "                    try:\n",
    "                        dic = {}\n",
    "                        UID = inner_page_bs.select('div.memberBadging.g10n')[num].select('div')[0]['id']\\\n",
    "                            .split('-')[0]\\\n",
    "                            .replace('UID_','')\n",
    "                            #使用者ID#\n",
    "                        UID= UID.split(' ')\n",
    "                        for UID_number in UID:\n",
    "                            if UID_number not in dic:\n",
    "                                dic[UID_number] = 1                               \n",
    "                            else:\n",
    "                                print(\"UID_number 重複值\")\n",
    "                                dic[UID_number] += 1\n",
    "#                         print(UID)\n",
    "                        print(dic)\n",
    "                    except IndexError:\n",
    "                        print(\"==============\")\n",
    "                        print(\"UID空值\")\n",
    "\n",
    "        except IndexError:\n",
    "                print(\"=====================\")\n",
    "                print(\"出現Skip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_homepage='https://www.tripadvisor.com.tw/members/doris7116'\n",
    "# https://www.tripadvisor.com.tw/MemberProfile-a_uid.3806B087E1EEEDBA38F7E690310B5144\n",
    "#     'https://www.tripadvisor.com.tw/members/doris7116'\n",
    "user_res2 = rs.get(user_homepage)\n",
    "print(user_res2)\n",
    "user_soup2 = bs(user_res2.text,'html5lib')\n",
    "user_year=user_soup2.select('div.modules-membercenter-member-profile')[0].select('div.ageSince')[0].text\n",
    "match=re.search(r'\\d{2}-\\d{2}', user_year)\n",
    "if match:\n",
    "    member_year=match.group(0)\n",
    "    print(member_year)\n",
    "else:\n",
    "    print(\"not found\")\n",
    "    member_year='null'\n",
    "# print(\"3\"+user_year)    \n",
    "user_gender=user_soup2.select('div.modules-membercenter-member-profile')[0].select('div.ageSince')[0].text.encode('utf-8')\n",
    "# print(\"3-1\"+user_gender) \n",
    "gender=['預設值','男性','女性']\n",
    "for i in range(0,3):\n",
    "    match=re.search(gender[i],user_gender)\n",
    "    if match:        \n",
    "        user_gender=user_gender.replace(gender[i],str(i))\n",
    "#         print(user_gender)\n",
    "        match = re.search(r'\\d', user_gender)\n",
    "        gender_id=match.group(0)\n",
    "        print(gender_id)\n",
    "    else:\n",
    "#         print(\"not found\")\n",
    "         gender_id='null'  \n",
    "user_country=user_soup2.select('div.modules-membercenter-member-profile')[0].select('div.hometown')[0].text\n",
    "user_country='台灣台中市'\n",
    "country=['0','台灣','香港','馬來西亞','新加坡','美國','加拿大','澳洲','紐西蘭','英國','中國','韓國','日本','印尼','泰國','法國','德國','俄羅斯','哈薩克','葡萄牙','巴西','西班牙','阿根廷','秘魯','荷蘭','義大利']\n",
    "for i in range(0,25):\n",
    "    match=re.search(country[i],user_country)\n",
    "    if match:\n",
    "        country_id=user_country.replace(country[i],str(i))\n",
    "#         print(country_id)\n",
    "        match = re.search(r'\\d+', country_id)\n",
    "        country_id=match.group(0)\n",
    "        print(country_id)\n",
    "    else:\n",
    "#         print(\"not found\")\n",
    "         country_id='null'\n",
    "# print(\"4\"+user_country)\n",
    "user_name_info = user_soup2.select('div.modules-membercenter-progress-header')[0].select('div.name')[0].text\n",
    "# print(\"4\"+user_name_info)\n",
    "# user_point = user_soup2.select('div.points_info.tripcollectiveinfo')[0].text\n",
    "# print(\"5\"+user_point)\n",
    "user_lv = user_soup2.select('div.level.tripcollectiveinfo')[0].text\n",
    "print(\"6\"+user_lv)\n",
    "match=re.search(r'\\d',user_lv)\n",
    "if match:\n",
    "    user_lv=match.group(0)\n",
    "    print(user_lv)\n",
    "else:\n",
    "    user_lv='null'\n",
    "    \n",
    "num = len(user_soup2.select('li.content-info'))\n",
    "for i in range(0,num):\n",
    "    comm_times = user_soup2.select('li.content-info')[i].select('a')[0]    \n",
    "#     print(r['name'].decode('utf-8'))\n",
    "    if comm_times['name'].decode('utf-8') == 'reviews': \n",
    "#         print(comm_times.text)\n",
    "        match=re.search(r'\\d*',comm_times.text)\n",
    "        if match:            \n",
    "            comm_times=match.group(0)\n",
    "            print(comm_times)\n",
    "            comm_times=comm_times            \n",
    "#         else:\n",
    "#         comm_times='null'       \n",
    "    else:        \n",
    "        comm_times='null'\n",
    "    comm_times = user_soup2.select('li.content-info')[i].select('a')[0]     \n",
    "    if comm_times['name'].decode('utf-8') == 'ratings':\n",
    "#         print(comm_times.text)\n",
    "        match=re.search(r'\\d*',comm_times.text)\n",
    "        if match:            \n",
    "            comm_raking=match.group(0)\n",
    "            print(comm_raking)\n",
    "            comm_raking=comm_raking            \n",
    "#         else:\n",
    "#         comm_times='null'       \n",
    "    else:        \n",
    "        comm_raking='null'   \n",
    "\n",
    "# print(\"8\"+user_cont_info)\n",
    "# print(len(user_cont_info))\n",
    "# match=re.search(r'\\d+'+'評論',user_cont_info)\n",
    "# user_cont_info=match.group(0)\n",
    "# print(user_cont_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0912345678\n",
      "0922\n",
      "0911\n",
      "09123482384060192381\n",
      "=====================\n",
      "0912345678\n",
      "0922-222-222\n",
      "0911-222333\n",
      "0912348238\n"
     ]
    }
   ],
   "source": [
    "phones = ['我的電話是 0912345678 Call Me', '0922-222-222 我餓了', \\\n",
    "          '等妳呦 0911-222333', '真心不騙 09123482384060192381']\n",
    "\n",
    "for phone in phones:\n",
    "    m = re.search(r'09\\d+', phone)\n",
    "    print(m.group(0))\n",
    "print(\"=====================\")\n",
    "for phone in phones:\n",
    "    m = re.search(r'09\\d{2}-?\\d{3}-?\\d{3}', phone) # r'09\\d\\d'\n",
    "    print(m.group(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "not found\n",
      "not found\n",
      "not found\n",
      "not found\n",
      "not found\n",
      "not found\n",
      "not found\n",
      "not found\n",
      "not found\n",
      "not found\n",
      "not found\n",
      "not found\n",
      "not found\n",
      "not found\n",
      "not found\n",
      "not found\n",
      "not found\n",
      "not found\n",
      "not found\n",
      "not found\n",
      "not found\n",
      "not found\n",
      "not found\n",
      "not found\n",
      "not found\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import requests as rs\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from datetime import date,datetime\n",
    "import json\n",
    "# from splinter import Browser\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import NoAlertPresentException\n",
    "import unittest, time, re\n",
    "user_homepage='https://www.tripadvisor.com.tw/members/singaDaave'\n",
    "user_res2 = rs.get(user_homepage)\n",
    "print(user_res2)\n",
    "user_soup2 = bs(user_res2.text,'html5lib')\n",
    "user_country=user_soup2.select('div.modules-membercenter-member-profile')[0].select('div.hometown')[0].text.encode('utf-8')\n",
    "\n",
    "\n",
    "country=['0','台灣','香港','馬來西亞','新加坡','美國','加拿大','澳洲','紐西蘭','英國','中國','韓國','日本','印尼','泰國','法國','德國','俄羅斯','哈薩克','葡萄牙','巴西','西班牙','阿根廷','秘魯','荷蘭','義大利']\n",
    "for i in range(0,25):\n",
    "    match=re.search(country[i],user_country)\n",
    "    if match:\n",
    "        country_id=user_country.replace(country[i],str(i))\n",
    "        print(country_id)\n",
    "        match = re.search(r'\\d+', country_id)\n",
    "        country_id=match.group(0)\n",
    "        print(country_id)\n",
    "    else:\n",
    "        print(\"not found\")\n",
    "        country_id='null'\n",
    "        \n",
    "# 1\t台灣\n",
    "# 2\t香港\n",
    "# 3\t馬來西亞\n",
    "# 4\t新加坡\n",
    "# 5\t美國\n",
    "# 6\t加拿大\n",
    "# 7\t澳洲\n",
    "# 8\t紐西蘭\n",
    "# 9\t英國\n",
    "# 10\t中國\n",
    "# 11\t韓國\n",
    "# 12\t日本\n",
    "# 13\t印尼\n",
    "# 14\t泰國\n",
    "# 15\t法國\n",
    "# 16\t德國\n",
    "# 17\t俄羅斯\n",
    "# 18\t哈薩克\n",
    "# 19\t葡萄牙\n",
    "# 20\t巴西\n",
    "# 21\t西班牙\n",
    "# 22\t阿根廷\n",
    "# 23\t秘魯\n",
    "# 24\t荷蘭\n",
    "# 25\t義大利"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "user_target='饕客 背包客 家庭渡假旅客 安詳與寧靜追尋者 尋求經濟實惠旅行的旅客'\n",
    "print(type(user_target))\n",
    "style=['0','注重豪華旅遊的旅客','家庭渡假旅客','60歲以上旅客','海灘愛好者','都市探索者','素食主義者','尋求刺激的旅客','自然愛好者','安詳與寧靜追尋者','饕客','夜生活愛好者','儉約的旅客','引領流行的旅客','熱衷購物的旅客','熟悉當地環境的旅客','尋求經濟實惠旅行的旅客','背包客','藝術與建築愛好者','歷史愛好者']\n",
    "for i in range(0,19):\n",
    "    match=re.search(style[i],user_target)\n",
    "    if match:        \n",
    "        user_target=user_target.replace(style[i],str(i))    \n",
    "print(user_target)\n",
    "# 1. luxury : 注重豪華旅遊的旅客\n",
    "# 2. family_travel: 家庭渡假旅客\n",
    "# 3.  over_60yrs : 60 歲以上旅客\n",
    "# 4. beach_lover : 海灘愛好者\n",
    "# 5. city_lover: 都市探索者\n",
    "# 6. vegetarian: 素食主義者\n",
    "# 7. excited_lover : 尋求刺激的旅客\n",
    "# 8. natural_lover : 自然愛好者\n",
    "# 9. peace_lover : 安詳與寧靜追尋者\n",
    "# 10. food_lover : 饕客\n",
    "# 11. nightlife_lover : 夜生活愛好者\n",
    "# 12. frugal_traveler : 儉約的旅客\n",
    "# 13. fashion_leader : 引領流行的旅客\n",
    "# 14. shopping_lover: 熱衷購物的旅客\n",
    "# 15. localguide_traveler : 熟悉當地環境的旅客\n",
    "# 16. highCP_persuer : 尋求經濟實惠旅行的旅客\n",
    "# 17. backpackers: 背包客\n",
    "# 18. arts_lover : 藝術與建築愛好者\n",
    "# 19. history_lover : 歷史愛好者\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_homepage='https://www.tripadvisor.com.tw/members/doris7116'\n",
    "user_res2 = rs.get(user_homepage)\n",
    "print(user_res2)\n",
    "user_soup2 = bs(user_res2.text,'html5lib')\n",
    "user_year=user_soup2.select('div.modules-membercenter-member-profile')[0].select('div.ageSince')[0].text\n",
    "match=re.search(r'\\d{2}-\\d{2}', user_year)\n",
    "if match:\n",
    "    member_year=match.group(0)\n",
    "    print(member_year)\n",
    "else:\n",
    "    print(\"not found\")\n",
    "    member_year='null'\n",
    "# print(user_year)\n",
    "# print(type(user_year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# user_homepage='https://www.tripadvisor.com.tw/members/doris7116'\n",
    "# user_res2 = rs.get(user_homepage)\n",
    "# print(user_res2)\n",
    "# user_soup2 = bs(user_res2.text,'html5lib')\n",
    "# user_year=user_soup2.select('div.modules-membercenter-member-profile')[0].select('div.ageSince')[0].text\n",
    "# match=re.search(r'\\d{2}-\\d{2}', user_year)\n",
    "# if match:\n",
    "#     member_year=match.group(0)\n",
    "#     print(member_year)\n",
    "# else:\n",
    "#     print(\"not found\")\n",
    "#     member_year='null'\n",
    "\n",
    "# try:\n",
    "#                             gender=user_soup2.select('div.modules-membercenter-member-profile')[0].select('div.ageSince')[0].text.encode('utf-8')                        \n",
    "#                             print(gender)\n",
    "#                             genders=['預設值','男性','女性','男','女']\n",
    "#                             for i in range(0,5):\n",
    "#                                 match=re.search(genders[i],gender)                                                               \n",
    "#                                 if match:\n",
    "#                                     print(match.group(0))\n",
    "#                                     gender=match.group(0)\n",
    "#                                     print(gender)\n",
    "# #                                     gender=match.group(0)\n",
    "# #                                     print(gender)\n",
    "# #                                     gender=gender\n",
    "# #                                     print(\"***********\")\n",
    "# #                                     print(gender)\n",
    "# #                                     print(type(gender))\n",
    "#                                 else: \n",
    "#                                     gender='null'\n",
    "#     #                                     print(\"not found\")\n",
    "#                         except:\n",
    "#                             gender='null'            \n",
    "user_gender='註冊時間：2014年11月 25-34 歲 男性  '\n",
    "print(user_gender)\n",
    "s=len(user_gender.split())\n",
    "print(s)\n",
    "genders=['預設值','男性','女性','男','女']\n",
    "for i in range(0,4):    \n",
    "    match=re.search(gender[i],user_gender)\n",
    "    if match:\n",
    "        user_gender=user_gender.replace(gender[i],str(i)) \n",
    "        print(user_gender)\n",
    "    else: \n",
    "        print(\"not found\")\n",
    "#         user_gender='null'\n",
    "    \n",
    "        print(\"3\"+user_gender)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "user_homepage='https://www.tripadvisor.com.tw/members/%E8%93%8B%E7%91%9E%E7%89%B9'\n",
    "# https://www.tripadvisor.com.tw/members/%E8%93%8B%E7%91%9E%E7%89%B9\n",
    "user_res2 = rs.get(user_homepage)\n",
    "print(user_res2)\n",
    "user_soup2 = bs(user_res2.text,'html5lib')\n",
    "user_year=user_soup2.select('div.modules-membercenter-member-profile')[0].select('div.ageSince')[0].text\n",
    "match=re.search(r'\\d{2}-\\d{2}', user_year)\n",
    "if match:\n",
    "    member_year=match.group(0)\n",
    "    print(member_year)\n",
    "else:\n",
    "    print(\"not found\")\n",
    "    member_year='null'\n",
    "print(\"3\"+user_year)    \n",
    "user_country=user_soup2.select('div.modules-membercenter-member-profile')[0].select('div.ageSince')[0].text.encode('utf-8')\n",
    "print(user_country)\n",
    "country=['預設值','男性','女性']\n",
    "for i in range(0,3):\n",
    "    match=re.search(country[i],user_country)\n",
    "    if match:\n",
    "        print(country[i])\n",
    "#         user_country=user_country.replace(country[i],str(i))\n",
    "#         print(user_country)\n",
    "#         match = re.search(r'\\d', user_country)\n",
    "#         print(match.group(0))\n",
    "#         country_id=match.group(0)\n",
    "#         print(country_id)\n",
    "     else:\n",
    "        print(\"not found\")\n",
    "        country_id='null'\n",
    "\n",
    "# user_target='饕客 背包客 家庭渡假旅客 安詳與寧靜追尋者 尋求經濟實惠旅行的旅客'\n",
    "# print(type(user_target))\n",
    "# style=['0','注重豪華旅遊的旅客','家庭渡假旅客','60歲以上旅客','海灘愛好者','都市探索者','素食主義者','尋求刺激的旅客','自然愛好者','安詳與寧靜追尋者','饕客','夜生活愛好者','儉約的旅客','引領流行的旅客','熱衷購物的旅客','熟悉當地環境的旅客','尋求經濟實惠旅行的旅客','背包客','藝術與建築愛好者','歷史愛好者']\n",
    "# for i in range(0,19):\n",
    "#     match=re.search(style[i],user_target)\n",
    "#     if match:        \n",
    "#         user_target=user_target.replace(style[i],str(i))    \n",
    "# print(user_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = ('https://www.tripadvisor.com.tw/members/tsai95862016')\n",
    "res = rs.get(url)\n",
    "soup = bs(res.text,'html5lib')\n",
    "num = len(soup.select('li.content-info'))\n",
    "for i in range(0,num):\n",
    "\n",
    "    r = soup.select('li.content-info')[i].select('a')[0]\n",
    "    \n",
    "#     print(r['name'].decode('utf-8'))\n",
    "    if r['name'].decode('utf-8') == 'reviews':\n",
    "        print(r.text)\n",
    "    elif r['name'].decode('utf-8') == 'ratings':\n",
    "        print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = ('https://www.tripadvisor.com.tw/members/tsai95862016')\n",
    "res = rs.get(url)\n",
    "soup = bs(res.text,'html5lib')\n",
    "num = len(soup.select('li.content-info'))\n",
    "for i in range(0,num):\n",
    "    comm_times = soup.select('li.content-info')[i].select('a')[0]    \n",
    "#     print(r['name'].decode('utf-8'))\n",
    "    if comm_times['name'].decode('utf-8') == 'reviews': \n",
    "#         print(comm_times.text)\n",
    "        match=re.search(r'\\d...',comm_times.text)\n",
    "        if match:            \n",
    "            comm_times=match.group(0)\n",
    "            print(comm_times)\n",
    "            comm_times=comm_times            \n",
    "#         else:\n",
    "#         comm_times='null'       \n",
    "    else:        \n",
    "        comm_times='null'\n",
    "    comm_times = soup.select('li.content-info')[i].select('a')[0]     \n",
    "    if comm_times['name'].decode('utf-8') == 'ratings':\n",
    "#         print(comm_times.text)\n",
    "        match=re.search(r'\\d...',comm_times.text)\n",
    "        if match:            \n",
    "            comm_raking=match.group(0)\n",
    "            print(comm_raking)\n",
    "            comm_raking=comm_raking            \n",
    "#         else:\n",
    "#         comm_times='null'       \n",
    "    else:        \n",
    "        comm_raking='null'   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import requests as rs\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from datetime import date,datetime\n",
    "import json\n",
    "# from splinter import Browser\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import NoAlertPresentException\n",
    "import unittest, time, re\n",
    "home_url = 'https://www.tripadvisor.com.tw'\n",
    "base_url='https://www.tripadvisor.com.tw/Attractions-g293913-Activities-oa{}-Taipei.html#ATTRACTION_LIST'\n",
    "textNo=0\n",
    "#景點分頁下載\n",
    "for page in xrange(0,14,+1):\n",
    "    title=(base_url.format(page*30))\n",
    "#     print(title)\n",
    "    res=rs.get(title)\n",
    "    soup=bs(res.text,'html5lib')\n",
    "    for n in soup.select('.photo_booking.non_generic .photo_link'):    \n",
    "    #分頁網站連接下載\n",
    "        try:\n",
    "            url='https://www.tripadvisor.com.tw'+n['href']\n",
    "            if(url.split('_')[1].split('-')[0]=='Review'):\n",
    "                print(url)      \n",
    "            else:\n",
    "                url='null'\n",
    "                print(\"怪怪的\")\n",
    "            #============分頁挑選========#    \n",
    "            res=rs.get(url)\n",
    "            soup=bs(res.text,'html5lib')        \n",
    "            inner_url = url.replace('Reviews-','Reviews-or{}-')\n",
    "#             print(\"1\"+ inner_url)\n",
    "            #==========各景點評論的初始頁==================#\n",
    "            content = inner_url.split('-')[3].split('-')[0]\n",
    "            total_page =int(soup.select('.unified.pagination .pageNum.taLnk')[-1]['data-page-number'])\n",
    "            print(total_page)\n",
    "            #=====各評論的總頁數===================#\n",
    "            for page in xrange(0,total_page-1):\n",
    "                inner_title = (inner_url.format(page*10))    \n",
    "#                 print(\"2\"+ inner_title)\n",
    "                #===========各評論的評論內容========#    \n",
    "                inner_page_res = rs.get(inner_title)\n",
    "                inner_page_bs = bs(inner_page_res.text ,'html5lib')\n",
    "                total_userId = len(inner_page_bs.select('div.memberBadging.g10n'))\n",
    "                for num in range(0,total_userId,+1):               \n",
    "                    try:\n",
    "                        UID = inner_page_bs.select('div.memberBadging.g10n')[num].select('div')[0]['id']\\\n",
    "                            .split('-')[0]\\\n",
    "                            .replace('UID_','')\n",
    "                            #使用者ID#\n",
    "                        member_id = UID  \n",
    "                        print(UID)                       \n",
    "                        user_url = 'https://www.tripadvisor.com.tw/MemberOverlay?Mode=owa&uid={}&c=&src=&fus=false&partner=false&LsoId=&metaReferer=Attraction_Review'\n",
    "                        user_infopage = (user_url.format(UID))\n",
    "                        print(user_infopage)\n",
    "                        print(\"++++++++++++++++++++++++++\")\n",
    "                        #各使用者簡介#\n",
    "                        user_res = rs.get(user_infopage)\n",
    "                        user_soup = bs(user_res.text,'html5lib')\n",
    "#                                         print(user_soup.select('div.memberreviewbadge')[0].select('div.badgeinfo')[0].text)\n",
    "                        def user_function (a,b):\n",
    "                            return user_soup.select(a)[0].select(b)[0].text                \n",
    "                        user_name = user_function('.memberOverlayRedesign.g10n','.username')                        \n",
    "#                         print(user_name)                        \n",
    "                        user_time = user_function('.memberOverlayRedesign.g10n','.memberdescription')\n",
    "#                         print(type(user_time))\n",
    "#                         print(\"1\"+user_time)\n",
    "                        user_counts = user_function('.memberOverlayRedesign.g10n','.counts')\n",
    "                        member_remark=user_counts\n",
    "#                         print(\"2\"+member_remark)\n",
    "                        user_homepage = home_url + user_soup.select('div.baseNav')[0].select('a')[0]['href']\n",
    "                        print(user_homepage)\n",
    "#                         user_homepage='https://www.tripadvisor.com.tw/members/doris7116'\n",
    "                        # https://www.tripadvisor.com.tw/MemberProfile-a_uid.3806B087E1EEEDBA38F7E690310B5144\n",
    "                        #     'https://www.tripadvisor.com.tw/members/doris7116'\n",
    "                        user_res2 = rs.get(user_homepage)\n",
    "                        print(user_res2)\n",
    "                        user_soup2 = bs(user_res2.text,'html5lib')\n",
    "                        user_year=user_soup2.select('div.modules-membercenter-member-profile')[0].select('div.ageSince')[0].text\n",
    "                        match=re.search(r'\\d{2}-\\d{2}', user_year)\n",
    "                        if match:\n",
    "                            print(user_year)\n",
    "                            member_year=match.group(0)\n",
    "                            print(member_year)\n",
    "                        else:\n",
    "                            print(\"not found\")\n",
    "                            member_year='null'\n",
    "                        # print(\"3\"+user_year)                        \n",
    "                        try:\n",
    "                            gender=user_soup2.select('div.modules-membercenter-member-profile')[0].select('div.ageSince')[0].text.encode('utf-8')                            \n",
    "                            print(gender)\n",
    "#                             print(\"11111111\")\n",
    "                            s=len(user_soup2.select('div.modules-membercenter-member-profile')[0].select('div.ageSince')[0].text.encode('utf-8').split())\n",
    "#                             print(s)                            \n",
    "                            for y in range(0,s):               \n",
    "                                gender=user_soup2.select('div.modules-membercenter-member-profile')[0].select('div.ageSince')[0].text.encode('utf-8').split()[y]\n",
    "#                                 print(gender)                            \n",
    "                                s=['預設值','男','女']\n",
    "                                for i in range(0,3):\n",
    "                                    match=re.search(s[i],gender)\n",
    "#                                     print(\"------------\")                                \n",
    "                                    if match:\n",
    "                                        d=gender.replace(s[i],str(i))\n",
    "                                        match=re.search(r'\\d', d)\n",
    "                                        gender=match.group(0)\n",
    "                                        print(gender)\n",
    "                   \n",
    "                        except:\n",
    "                            gender='null'\n",
    "                        #======gender==========#    \n",
    "                        user_country=user_soup2.select('div.modules-membercenter-member-profile')[0].select('div.hometown')[0].text.encode('utf-8')\n",
    "                        print(user_country)\n",
    "                        country=['0','台灣','香港','馬來西亞','新加坡','美國','加拿大','澳洲','紐西蘭','英國','中國','韓國','日本','印尼','泰國','法國','德國','俄羅斯','哈薩克','葡萄牙','巴西','西班牙','阿根廷','秘魯','荷蘭','義大利','南韓']\n",
    "                        for i in range(0,26):\n",
    "                            match=re.search(country[i],user_country)\n",
    "                            if match:\n",
    "                                country_id=user_country.replace(country[i],str(i))\n",
    "                                print(country_id)\n",
    "                                match = re.search(r'\\d+', country_id)\n",
    "                                country_id=match.group(0)\n",
    "                                print(country_id)\n",
    "                            else:\n",
    "#                                 print(\"not found\")\n",
    "                                country_id='null'\n",
    "                        # print(\"4\"+user_country)\n",
    "                        user_name_info = user_soup2.select('div.modules-membercenter-progress-header')[0].select('div.name')[0].text\n",
    "                        # print(\"4\"+user_name_info)\n",
    "                        # user_point = user_soup2.select('div.points_info.tripcollectiveinfo')[0].text\n",
    "                        # print(\"5\"+user_point)\n",
    "                        user_lv = user_soup2.select('div.level.tripcollectiveinfo')[0].text\n",
    "                        print(user_lv)\n",
    "                        match=re.search(r'\\d',user_lv)\n",
    "                        if match:\n",
    "                            user_lv=match.group(0)\n",
    "                            print(user_lv)\n",
    "                        else:\n",
    "                            user_lv='null'\n",
    "                        try:        \n",
    "                            num = len(user_soup2.select('li.content-info'))\n",
    "                        except:\n",
    "                            comm_times='null'\n",
    "                            ranking_times='null'\n",
    "                        for i in range(0,num):\n",
    "                            comm = user_soup2.select('li.content-info')[i].select('a')[0]    \n",
    "                        #     print(r['name'].decode('utf-8'))\n",
    "                            try:\n",
    "                                if comm['name'].decode('utf-8') == 'reviews': \n",
    "                                    print(comm.text)\n",
    "                                    match=re.search(r'\\d*',comm.text)\n",
    "                                    if match:\n",
    "                                        comm=match.group(0) \n",
    "                                        comm_times=comm   \n",
    "                                        print(comm_times)\n",
    "    #                                     print(type(comm_times))                                    \n",
    "                            #         else:\n",
    "                            #         comm_times='null'       \n",
    "                                else:        \n",
    "                                    comm_times='null'\n",
    "                            except:\n",
    "                                comm_times='null'\n",
    "                            #====評論次數===#     \n",
    "                            comm = user_soup2.select('li.content-info')[i].select('a')[0] \n",
    "                            try:\n",
    "                                if comm['name'].decode('utf-8') == 'ratings':\n",
    "                                    print(comm.text)\n",
    "                                    match=re.search(r'\\d*',comm.text)\n",
    "                                    if match:            \n",
    "                                        comm=match.group(0)                                    \n",
    "                                        ranking_times=comm\n",
    "                                        print(ranking_times)\n",
    "#                                         print(type(ranking_times))\n",
    "                            #         else:\n",
    "                            #         comm_times='null'       \n",
    "                                else:        \n",
    "                                    ranking_times='null'\n",
    "                            except:\n",
    "                                ranking_times='null'        \n",
    "                            #====評等次數===#       \n",
    "\n",
    "                        # print(\"8\"+user_cont_info)\n",
    "                        # print(len(user_cont_info))\n",
    "                        # match=re.search(r'\\d+'+'評論',user_cont_info)\n",
    "                        # user_cont_info=match.group(0)\n",
    "                        # print(user_cont_info)                  \n",
    "                    except:\n",
    "                        user_target = 'null'\n",
    "                        user_badge='null' \n",
    "                        user_lv='null' \n",
    "#                     finally:\n",
    "#                         print(\"ok1\")\n",
    "        except IndexError:\n",
    "                print(\"=====================\")\n",
    "                print(\"出現Skip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'user_soup2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ec8831879507>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgender\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muser_soup2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div.modules-membercenter-member-profile'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div.ageSince'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgender\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"11111111\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_soup2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div.modules-membercenter-member-profile'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div.ageSince'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'user_soup2' is not defined"
     ]
    }
   ],
   "source": [
    "gender=user_soup2.select('div.modules-membercenter-member-profile')[0].select('div.ageSince')[0].text.encode('utf-8')                            \n",
    "print(gender)\n",
    "print(\"11111111\")\n",
    "s=len(user_soup2.select('div.modules-membercenter-member-profile')[0].select('div.ageSince')[0].text.encode('utf-8').split())\n",
    "print(s)\n",
    "#                             d=user_soup2.select('div.modules-membercenter-member-profile')[0].select('div.ageSince')[0].text.encode('utf-8').split()[3]\n",
    "#                             print(d)\n",
    "for y in range(0,s):               \n",
    "    gender=user_soup2.select('div.modules-membercenter-member-profile')[0].select('div.ageSince')[0].text.encode('utf-8').split()[y]\n",
    "    print(gender)                            \n",
    "    s=['預設值','男性','女性','男','女']\n",
    "    for i in range(0,5):\n",
    "        match=re.search(s[i],gender)\n",
    "        print(\"------------\")                                \n",
    "        if match:\n",
    "            d=gender.replace(s[i],str(i))\n",
    "            print(\"+++++++++\")\n",
    "            print(d)\n",
    "#                                     gender=match.group(0)\n",
    "#                                     print(gender)\n",
    "#                                     gender=gender\n",
    "#                                     print(\"***********\")\n",
    "#                                     print(gender)\n",
    "#                                     print(type(gender))\n",
    "        else:\n",
    "\n",
    "            gender='null'\n",
    "            print(\"not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import requests as rs\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from datetime import date,datetime\n",
    "import json\n",
    "# from splinter import Browser\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import NoAlertPresentException\n",
    "import unittest, time, re\n",
    "home_url = 'https://www.tripadvisor.com.tw'\n",
    "base_url='https://www.tripadvisor.com.tw/Attractions-g293913-Activities-oa{}-Taipei.html#ATTRACTION_LIST'\n",
    "textNo=0\n",
    "#景點分頁下載\n",
    "for page in xrange(0,14,+1):\n",
    "    title=(base_url.format(page*30))\n",
    "#     print(title)\n",
    "    res=rs.get(title)\n",
    "    soup=bs(res.text,'html5lib')\n",
    "    for n in soup.select('.photo_booking.non_generic .photo_link'):    \n",
    "    #分頁網站連接下載\n",
    "        try:\n",
    "            url='https://www.tripadvisor.com.tw'+n['href']\n",
    "            if(url.split('_')[1].split('-')[0]=='Review'):\n",
    "                print(url)      \n",
    "            else:\n",
    "                url='null'\n",
    "                print(\"怪怪的\")\n",
    "            #============分頁挑選========#    \n",
    "            res=rs.get(url)\n",
    "            soup=bs(res.text,'html5lib')        \n",
    "            inner_url = url.replace('Reviews-','Reviews-or{}-')\n",
    "#             print(\"1\"+ inner_url)\n",
    "            #==========各景點評論的初始頁==================#\n",
    "            content = inner_url.split('-')[3].split('-')[0]\n",
    "            total_page =int(soup.select('.unified.pagination .pageNum.taLnk')[-1]['data-page-number'])\n",
    "            print(total_page)\n",
    "            #=====各評論的總頁數===================#\n",
    "            for page in xrange(0,total_page-1):\n",
    "                inner_title = (inner_url.format(page*10))    \n",
    "#                 print(\"2\"+ inner_title)\n",
    "                #===========各評論的評論內容========#    \n",
    "                inner_page_res = rs.get(inner_title)\n",
    "                inner_page_bs = bs(inner_page_res.text ,'html5lib')\n",
    "                total_userId = len(inner_page_bs.select('div.memberBadging.g10n'))\n",
    "                for num in range(0,total_userId,+1):               \n",
    "                    try:\n",
    "                        UID = inner_page_bs.select('div.memberBadging.g10n')[num].select('div')[0]['id']\\\n",
    "                            .split('-')[0]\\\n",
    "                            .replace('UID_','')\n",
    "                            #使用者ID#\n",
    "                        member_id = UID  \n",
    "                        print(UID)                       \n",
    "                        user_url = 'https://www.tripadvisor.com.tw/MemberOverlay?Mode=owa&uid={}&c=&src=&fus=false&partner=false&LsoId=&metaReferer=Attraction_Review'\n",
    "                        user_infopage = (user_url.format(UID))\n",
    "                        print(user_infopage)\n",
    "                        print(\"++++++++++++++++++++++++++\")\n",
    "                        #各使用者簡介#\n",
    "                        user_res = rs.get(user_infopage)\n",
    "                        user_soup = bs(user_res.text,'html5lib')\n",
    "#                                         print(user_soup.select('div.memberreviewbadge')[0].select('div.badgeinfo')[0].text)\n",
    "                        def user_function (a,b):\n",
    "                            return user_soup.select(a)[0].select(b)[0].text                \n",
    "                        user_name = user_function('.memberOverlayRedesign.g10n','.username')                        \n",
    "#                         print(user_name)                        \n",
    "                        user_time = user_function('.memberOverlayRedesign.g10n','.memberdescription')\n",
    "#                         print(type(user_time))\n",
    "#                         print(\"1\"+user_time)\n",
    "                        user_counts = user_function('.memberOverlayRedesign.g10n','.counts')\n",
    "                        member_remark=user_counts\n",
    "#                         print(\"2\"+member_remark)\n",
    "                        user_homepage = home_url + user_soup.select('div.baseNav')[0].select('a')[0]['href']\n",
    "                        print(user_homepage)\n",
    "#                         user_homepage='https://www.tripadvisor.com.tw/members/doris7116'\n",
    "                        # https://www.tripadvisor.com.tw/MemberProfile-a_uid.3806B087E1EEEDBA38F7E690310B5144\n",
    "                        #     'https://www.tripadvisor.com.tw/members/doris7116'\n",
    "                        user_res2 = rs.get(user_homepage)\n",
    "                        print(user_res2)\n",
    "                        user_soup2 = bs(user_res2.text,'html5lib')\n",
    "                        user_year=user_soup2.select('div.modules-membercenter-member-profile')[0].select('div.ageSince')[0].text\n",
    "                        match=re.search(r'\\d{2}-\\d{2}', user_year)\n",
    "                        if match:\n",
    "                            print(user_year)\n",
    "                            member_year=match.group(0)\n",
    "                            print(member_year)\n",
    "                        else:\n",
    "                            print(\"not found\")\n",
    "                            member_year='null'\n",
    "                        # print(\"3\"+user_year)                        \n",
    "                        try:\n",
    "                            gender=user_soup2.select('div.modules-membercenter-member-profile')[0].select('div.ageSince')[0].text.encode('utf-8')                            \n",
    "                            print(gender)\n",
    "#                             print(\"11111111\")\n",
    "                            s=len(user_soup2.select('div.modules-membercenter-member-profile')[0].select('div.ageSince')[0].text.encode('utf-8').split())\n",
    "#                             print(s)                            \n",
    "                            for y in range(0,s):               \n",
    "                                gender=user_soup2.select('div.modules-membercenter-member-profile')[0].select('div.ageSince')[0].text.encode('utf-8').split()[y]\n",
    "#                                 print(gender)                            \n",
    "                                s=['預設值','男','女']\n",
    "                                for i in range(0,3):\n",
    "                                    match=re.search(s[i],gender)\n",
    "#                                     print(\"------------\")                                \n",
    "                                    if match:\n",
    "                                        d=gender.replace(s[i],str(i))\n",
    "                                        match=re.search(r'\\d', d)\n",
    "                                        gender=match.group(0)\n",
    "                                        print(gender)\n",
    "                   \n",
    "                        except:\n",
    "                            gender='null'\n",
    "                        #======gender==========#    \n",
    "                        user_country=user_soup2.select('div.modules-membercenter-member-profile')[0].select('div.hometown')[0].text.encode('utf-8')\n",
    "                        print(user_country)\n",
    "                        country=['0','台灣','香港','馬來西亞','新加坡','美國','加拿大','澳洲','紐西蘭','英國','中國','韓國','日本','印尼','泰國','法國','德國','俄羅斯','哈薩克','葡萄牙','巴西','西班牙','阿根廷','秘魯','荷蘭','義大利','南韓']\n",
    "                        for i in range(0,26):\n",
    "                            match=re.search(country[i],user_country)\n",
    "                            if match:\n",
    "                                country_id=user_country.replace(country[i],str(i))\n",
    "                                print(country_id)\n",
    "                                match = re.search(r'\\d+', country_id)\n",
    "                                country_id=match.group(0)\n",
    "                                print(country_id)\n",
    "                            else:\n",
    "                                country_id='null'\n",
    "                        user_name_info = user_soup2.select('div.modules-membercenter-progress-header')[0].select('div.name')[0].text\n",
    "                        user_lv = user_soup2.select('div.level.tripcollectiveinfo')[0].text\n",
    "                        print(user_lv)\n",
    "                        match=re.search(r'\\d',user_lv)\n",
    "                        if match:\n",
    "                            user_lv=match.group(0)\n",
    "                            print(user_lv)\n",
    "                        else:\n",
    "                            user_lv='null'\n",
    "                        try:        \n",
    "                            num = len(user_soup2.select('li.content-info'))\n",
    "                        except:\n",
    "                            comm_times='null'\n",
    "                            ranking_times='null'\n",
    "                        for i in range(0,num):\n",
    "                            comm = user_soup2.select('li.content-info')[i].select('a')[0]                        \n",
    "                            try:\n",
    "                                if comm['name'].decode('utf-8') == 'reviews': \n",
    "                                    print(comm.text)\n",
    "                                    match=re.search(r'\\d*',comm.text)\n",
    "                                    if match:\n",
    "                                        comm=match.group(0) \n",
    "                                        comm_times=comm   \n",
    "                                        print(comm_times) \n",
    "                                else:        \n",
    "                                    comm_times='null'\n",
    "                            except:\n",
    "                                comm_times='null'\n",
    "                            #====評論次數===#     \n",
    "                            comm = user_soup2.select('li.content-info')[i].select('a')[0] \n",
    "                            try:\n",
    "                                if comm['name'].decode('utf-8') == 'ratings':\n",
    "                                    print(comm.text)\n",
    "                                    match=re.search(r'\\d*',comm.text)\n",
    "                                    if match:            \n",
    "                                        comm=match.group(0)                                    \n",
    "                                        ranking_times=comm\n",
    "                                        print(ranking_times)\n",
    "#                                         print(type(ranking_times))\n",
    "                            #         else:\n",
    "                            #         comm_times='null'       \n",
    "                                else:        \n",
    "                                    ranking_times='null'\n",
    "                            except:\n",
    "                                ranking_times='null'        \n",
    "                            #====評等次數===#       \n",
    "\n",
    "                        # print(\"8\"+user_cont_info)\n",
    "                        # print(len(user_cont_info))\n",
    "                        # match=re.search(r'\\d+'+'評論',user_cont_info)\n",
    "                        # user_cont_info=match.group(0)\n",
    "                        # print(user_cont_info)                  \n",
    "                    except:\n",
    "                        user_target = 'null'\n",
    "                        user_badge='null' \n",
    "                        user_lv='null' \n",
    "#                     finally:\n",
    "#                         print(\"ok1\")\n",
    "        except IndexError:\n",
    "                print(\"=====================\")\n",
    "                print(\"出現Skip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
